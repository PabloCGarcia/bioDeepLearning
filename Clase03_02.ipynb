{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase03-02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5qO2XNZ/L5GLadn22AEu3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PabloCGarcia/bioDeepLearning/blob/main/Clase03_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66a5-1HvCiyg"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "# create a pipeline object\r\n",
        "pipe = make_pipeline(\r\n",
        "     StandardScaler(),\r\n",
        "     LogisticRegression()\r\n",
        ")\r\n",
        "\r\n",
        "# load the iris dataset and split it into train and test sets\r\n",
        "X, y = load_iris(return_X_y=True)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\r\n",
        "\r\n",
        "# fit the whole pipeline\r\n",
        "tmp = pipe.fit(X_train, y_train)\r\n",
        "print(tmp)\r\n",
        "# we can now use it like any other estimator\r\n",
        "accuracy_score(pipe.predict(X_test), y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJOL_LboGBvJ"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from scipy.stats import randint\r\n",
        "\r\n",
        "X, y = fetch_california_housing(return_X_y=True)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\r\n",
        "\r\n",
        "# define the parameter space that will be searched over\r\n",
        "param_distributions = {'n_estimators': randint(1, 5),\r\n",
        "                       'max_depth': randint(5, 10)}\r\n",
        "\r\n",
        "# now create a searchCV object and fit it to the data\r\n",
        "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\r\n",
        "                            n_iter=5,\r\n",
        "                            param_distributions=param_distributions,\r\n",
        "                            random_state=0)\r\n",
        "tmp= search.fit(X_train, y_train)\r\n",
        "print(tmp)\r\n",
        "print(search.best_params_)\r\n",
        "\r\n",
        "# the search object now acts like a normal random forest estimator\r\n",
        "# with max_depth=9 and n_estimators=4\r\n",
        "search.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWAZpt65Aa-h"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn import datasets\r\n",
        "\r\n",
        "# different learning rate schedules and momentum parameters\r\n",
        "params = [{'solver': 'sgd', 'learning_rate': 'constant', 'momentum': 0,\r\n",
        "           'learning_rate_init': 0.2},\r\n",
        "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\r\n",
        "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\r\n",
        "          {'solver': 'sgd', 'learning_rate': 'constant', 'momentum': .9,\r\n",
        "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\r\n",
        "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': 0,\r\n",
        "           'learning_rate_init': 0.2},\r\n",
        "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\r\n",
        "           'nesterovs_momentum': True, 'learning_rate_init': 0.2},\r\n",
        "          {'solver': 'sgd', 'learning_rate': 'invscaling', 'momentum': .9,\r\n",
        "           'nesterovs_momentum': False, 'learning_rate_init': 0.2},\r\n",
        "          {'solver': 'adam', 'learning_rate_init': 0.01}]\r\n",
        "\r\n",
        "labels = [\"constant learning-rate\", \"constant with momentum\",\r\n",
        "          \"constant with Nesterov's momentum\",\r\n",
        "          \"inv-scaling learning-rate\", \"inv-scaling with momentum\",\r\n",
        "          \"inv-scaling with Nesterov's momentum\", \"adam\"]\r\n",
        "\r\n",
        "plot_args = [{'c': 'red', 'linestyle': '-'},\r\n",
        "             {'c': 'green', 'linestyle': '-'},\r\n",
        "             {'c': 'blue', 'linestyle': '-'},\r\n",
        "             {'c': 'red', 'linestyle': '--'},\r\n",
        "             {'c': 'green', 'linestyle': '--'},\r\n",
        "             {'c': 'blue', 'linestyle': '--'},\r\n",
        "             {'c': 'black', 'linestyle': '-'}]\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8v4l2aUBLkz"
      },
      "source": [
        "iris = datasets.load_iris()\r\n",
        "data_sets = [(iris.data, iris.target),\r\n",
        "             (digits.data, digits.target)]\r\n",
        "\r\n",
        "name=\"Iris\"\r\n",
        "print(\"\\nlearning on dataset %s\" % name)\r\n",
        "ax.set_title(name)\r\n",
        "X = MinMaxScaler().fit_transform(X)\r\n",
        "mlps = []\r\n",
        "max_iter = 20\r\n",
        "\r\n",
        "for label, param in zip(labels, params):\r\n",
        "    print(\"training: %s\" % label)\r\n",
        "    mlp = MLPClassifier(verbose=0, random_state=0,\r\n",
        "                        max_iter=max_iter, **param)\r\n",
        "    mlp.fit(X, y)\r\n",
        "    mlps.append(mlp)\r\n",
        "    print(\"Training set score: %f\" % mlp.score(X, y))\r\n",
        "    print(\"Training set loss: %f\" % mlp.loss_)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofTDFSTRE-sr"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\r\n",
        "for mlp, label, args in zip(mlps, labels, plot_args):\r\n",
        "        ax.plot(mlp.loss_curve_, label=label, **args)\r\n",
        "\r\n",
        "fig.legend(ax.get_lines(), labels, ncol=3, loc=\"upper center\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljU1bO0MBM7t"
      },
      "source": [
        "digits = datasets.load_digits()\r\n",
        "\r\n",
        "name=\"digits\"\r\n",
        "print(\"\\nlearning on dataset %s\" % name)\r\n",
        "ax.set_title(name)\r\n",
        "X = MinMaxScaler().fit_transform(X)\r\n",
        "mlps = []\r\n",
        "max_iter = 15\r\n",
        "\r\n",
        "for label, param in zip(labels, params):\r\n",
        "    print(\"training: %s\" % label)\r\n",
        "    mlp = MLPClassifier(verbose=0, random_state=0,\r\n",
        "                        max_iter=max_iter, **param)\r\n",
        "    mlp.fit(X, y)\r\n",
        "    mlps.append(mlp)\r\n",
        "    print(\"Training set score: %f\" % mlp.score(X, y))\r\n",
        "    print(\"Training set loss: %f\" % mlp.loss_)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4yKWJQBFJb5"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\r\n",
        "for mlp, label, args in zip(mlps, labels, plot_args):\r\n",
        "        ax.plot(mlp.loss_curve_, label=label, **args)\r\n",
        "\r\n",
        "fig.legend(ax.get_lines(), labels, ncol=3, loc=\"upper center\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n0nhPHjxL7P"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.datasets import fetch_openml\r\n",
        "\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "\r\n",
        "mnist = fetch_openml(\"mnist_784\")\r\n",
        "# rescale the data, use the traditional train/test split\r\n",
        "X, y = mnist.data / 255., mnist.target\r\n",
        "X_train, X_test = X[:60000], X[60000:]\r\n",
        "y_train, y_test = y[:60000], y[60000:]\r\n",
        "\r\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\r\n",
        "                     solver='sgd', verbose=10, tol=1e-4, random_state=1)\r\n",
        "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\r\n",
        "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\r\n",
        "#                    learning_rate_init=.1)\r\n",
        "\r\n",
        "mlp.fit(X_train, y_train)\r\n",
        "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\r\n",
        "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\r\n",
        "\r\n",
        "fig, axes = plt.subplots(4, 4)\r\n",
        "# use global min / max to ensure all weights are shown on the same scale\r\n",
        "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\r\n",
        "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\r\n",
        "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\r\n",
        "               vmax=.5 * vmax)\r\n",
        "    ax.set_xticks(())\r\n",
        "    ax.set_yticks(())\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}